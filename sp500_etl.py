#!/usr/bin/env python3
"""
S&P 500 Stock ETL Pipeline
Forr√°a: Wikipedia S&P 500 lista
C√©l: stock_products t√°bla felt√∂lt√©se idempotens m√≥don

Haszn√°lat:
  python sp500_etl.py --dry-run (csak log, nem m√≥dos√≠t)
  python sp500_etl.py --full (teljes sync)
  python sp500_etl.py --validate (csak ellen≈ërz√©s)
"""

import requests
import pandas as pd
from bs4 import BeautifulSoup
import mysql.connector
from mysql.connector import Error as MySQLError
import logging
import json
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import argparse
import sys

# ============================================================================
# LOGGING SETUP
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('sp500_etl.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================================================
# KONFIGUR√ÅCI√ìS KONSTANSOK
# ============================================================================

WIKIPEDIA_URL = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
EXPECTED_ROW_COUNT = 503  # ¬±5
MYSQL_CONFIG = {
    'host': '192.168.10.100',  # Database server IP
    'user': 'webServer',
    'password': 'webServer192.168.20.100',  # webServer user jelsz√≥
    'database': 'newscred',  # Megl√©v≈ë DB
    'port': 3306,
    'use_pure': True,
}

# ============================================================================
# WIKIPEDIA PARSER
# ============================================================================

class WikipediaSP500Parser:
    """Wikipedia S&P 500 t√°bla parszel√©se"""
    
    REQUIRED_COLUMNS = ['Symbol', 'Security', 'GICSSector', 'GICS Sub-Industry']
    OPTIONAL_COLUMNS = ['CIK', 'Date added', 'Founded', 'Headquarters Location']
    
    def __init__(self):
        self.df = None
        self.errors = []
    
    def fetch_page(self) -> str:
        """Wikip√©dia oldal let√∂lt√©se"""
        try:
            logger.info(f"üì• Wiki oldal let√∂lt√©se: {WIKIPEDIA_URL}")
            
            # User-Agent header (Wikipedia blokkolja az alap√©rtelmez√©st)
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(WIKIPEDIA_URL, headers=headers, timeout=10)
            response.raise_for_status()
            logger.info(f"‚úÖ Wiki let√∂lt√©s OK ({len(response.content)} bytes)")
            return response.text
        except requests.RequestException as e:
            logger.error(f"‚ùå Wiki let√∂lt√©s hiba: {e}")
            raise
    
    def parse_html_table(self, html: str) -> pd.DataFrame:
        """HTML t√°bla parszel√©se"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            # Els≈ë t√°bl√°zat keres√©se
            table = soup.find('table', {'class': 'wikitable'})
            if not table:
                raise ValueError("Wikitable nem tal√°lhat√≥!")
            
            logger.info("üìä T√°bla parszel√©se...")
            
            # Oszlopok
            headers = []
            for th in table.find_all('th'):
                headers.append(th.get_text(strip=True))
            
            # Sorok
            rows = []
            for tr in table.find_all('tr')[1:]:  # Skip header
                cols = []
                for td in tr.find_all('td'):
                    cols.append(td.get_text(strip=True))
                if cols:
                    rows.append(cols)
            
            # DataFrame
            df = pd.DataFrame(rows, columns=headers)
            logger.info(f"‚úÖ Parszel√©s OK: {len(df)} sor, {len(df.columns)} oszlop")
            
            return df
        
        except Exception as e:
            logger.error(f"‚ùå Parszel√©s hiba: {e}")
            raise
    
    def validate_columns(self, df: pd.DataFrame) -> bool:
        """Oszlopok valid√°l√°sa"""
        missing = [col for col in self.REQUIRED_COLUMNS if col not in df.columns]
        
        if missing:
            logger.error(f"‚ùå Hi√°nyz√≥ oszlopok: {missing}")
            return False
        
        logger.info(f"‚úÖ Oszlopok OK: {', '.join(df.columns)}")
        return True
    
    def validate_row_count(self, df: pd.DataFrame) -> bool:
        """Sorok sz√°ma valid√°l√°sa"""
        row_count = len(df)
        min_count = EXPECTED_ROW_COUNT - 5
        max_count = EXPECTED_ROW_COUNT + 5
        
        if min_count <= row_count <= max_count:
            logger.info(f"‚úÖ Sorok sz√°ma OK: {row_count} (v√°rt: ~{EXPECTED_ROW_COUNT})")
            return True
        else:
            logger.error(f"‚ùå Sorok sz√°ma gyan√∫s: {row_count} (v√°rt: {min_count}-{max_count})")
            return False
    
    def normalize_ticker(self, ticker: str) -> str:
        """
        Ticker normaliz√°l√°sa
        - Pont (.) MEGTART√ÅSA (S&P 500 form√°tum)
        - Sz√≥k√∂z elt√°vol√≠t√°sa
        - Nagybet≈±s√≠t√©s
        """
        ticker = ticker.strip().upper()
        logger.debug(f"Ticker normaliz√°lva: '{ticker}'")
        return ticker
    
    def parse(self) -> pd.DataFrame:
        """Teljes parse flow"""
        html = self.fetch_page()
        df = self.parse_html_table(html)
        
        if not self.validate_columns(df):
            raise ValueError("Oszlop valid√°ci√≥ sikertelen!")
        
        if not self.validate_row_count(df):
            logger.warning("‚ö†Ô∏è Sorok sz√°ma gyan√∫s, de folytatunk...")
        
        # Normaliz√°l√°s
        df['Symbol'] = df['Symbol'].apply(self.normalize_ticker)
        
        self.df = df
        logger.info(f"‚úÖ Parse k√©sz: {len(df)} √©rv√©nyes sor")
        
        return df

# ============================================================================
# MYSQL ADATB√ÅZIS R√âTEG
# ============================================================================

class StockDatabase:
    """MySQL adatb√°zis m≈±veletek"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.connection = None
        self.cursor = None
    
    def connect(self) -> bool:
        """Csatlakoz√°s MySQL-hez"""
        try:
            self.connection = mysql.connector.connect(**self.config)
            self.cursor = self.connection.cursor(dictionary=True)
            logger.info(f"‚úÖ MySQL csatlakoz√°s: {self.config['host']}/{self.config['database']}")
            return True
        except MySQLError as e:
            logger.error(f"‚ùå MySQL hiba: {e}")
            return False
    
    def disconnect(self):
        """Csatlakoz√°s bez√°r√°sa"""
        if self.cursor:
            self.cursor.close()
        if self.connection:
            self.connection.close()
            logger.info("‚úÖ MySQL csatlakoz√°s bez√°rva")
    
    def get_exchange_id(self, exchange_name: str) -> Optional[int]:
        """Exchange ID keres√©se (NYSE/NASDAQ)"""
        query = """
        SELECT id FROM stock_exchanges 
        WHERE exchange_name = %s AND status = 'active'
        LIMIT 1
        """
        self.cursor.execute(query, (exchange_name,))
        result = self.cursor.fetchone()
        
        if result:
            logger.debug(f"Exchange ID '{exchange_name}': {result['id']}")
            return result['id']
        
        logger.warning(f"‚ö†Ô∏è Exchange nem tal√°lhat√≥: {exchange_name}")
        return None
    
    def get_existing_stock(self, ticker: str, exchange_id: int) -> Optional[Dict]:
        """Megl√©v≈ë r√©szv√©ny keres√©se"""
        query = """
        SELECT id, company_name, sector, industry, is_sp500, updated_at
        FROM stock_products 
        WHERE ticker = %s AND exchange_id = %s
        """
        self.cursor.execute(query, (ticker, exchange_id))
        return self.cursor.fetchone()
    
    def upsert_stock(self, stock_data: Dict, exchange_id: int, dry_run: bool = False) -> Tuple[bool, str]:
        """
        Idempotent UPSERT
        
        Logic:
          - Ha EXISTS: UPDATE (csak ha megv√°ltozott)
          - Ha NEM EXISTS: INSERT
          - is_sp500 = 1 mindk√©t esetben
        """
        
        ticker = stock_data['ticker']
        company_name = stock_data['company_name']
        sector = stock_data.get('sector')
        industry = stock_data.get('industry')
        
        existing = self.get_existing_stock(ticker, exchange_id)
        
        if existing:
            # UPDATE path
            existing_id = existing['id']
            
            # Megv√°ltozott-e az adat?
            changed = (
                existing['company_name'] != company_name or
                existing['sector'] != sector or
                existing['industry'] != industry or
                existing['is_sp500'] != 1
            )
            
            if changed:
                if dry_run:
                    logger.info(f"[DRY-RUN] UPDATE {ticker}: {company_name}")
                    return True, "UPDATE (dry-run)"
                
                update_query = """
                UPDATE stock_products 
                SET company_name = %s, sector = %s, industry = %s, 
                    is_sp500 = 1, updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
                """
                self.cursor.execute(update_query, 
                    (company_name, sector, industry, existing_id))
                self.connection.commit()
                
                logger.info(f"‚úèÔ∏è UPDATE: {ticker} ({existing_id})")
                return True, "UPDATE"
            else:
                logger.debug(f"‚è≠Ô∏è SKIP: {ticker} (nincs v√°ltoz√°s)")
                return False, "SKIP"
        
        else:
            # INSERT path
            if dry_run:
                logger.info(f"[DRY-RUN] INSERT {ticker}: {company_name}")
                return True, "INSERT (dry-run)"
            
            insert_query = """
            INSERT INTO stock_products 
            (exchange_id, ticker, company_name, sector, industry, 
             currency, status, is_sp500, created_at, updated_at)
            VALUES (%s, %s, %s, %s, %s, 'USD', 'active', 1, 
                    CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            """
            self.cursor.execute(insert_query,
                (exchange_id, ticker, company_name, sector, industry))
            self.connection.commit()
            
            logger.info(f"‚ûï INSERT: {ticker}")
            return True, "INSERT"

# ============================================================================
# ETL ORCHESTRATOR
# ============================================================================

class SP500ETLPipeline:
    """ETL Pipeline vez√©rl≈ë"""
    
    def __init__(self, mysql_config: Dict, dry_run: bool = False, validate_only: bool = False):
        self.mysql_config = mysql_config
        self.dry_run = dry_run
        self.validate_only = validate_only
        self.db = None
        self.parser = None
        self.stats = {
            'total_rows': 0,
            'inserted': 0,
            'updated': 0,
            'skipped': 0,
            'errors': 0,
        }
    
    def run(self) -> bool:
        """ETL teljes futtat√°sa"""
        logger.info("=" * 70)
        logger.info("üöÄ S&P 500 ETL Pipeline IND√çT√ÅS")
        logger.info(f"   M√≥d: {'DRY-RUN' if self.dry_run else 'FULL'}")
        logger.info("=" * 70)
        
        try:
            # 1. Wiki parse
            self.parser = WikipediaSP500Parser()
            df = self.parser.parse()
            self.stats['total_rows'] = len(df)
            
            if self.validate_only:
                logger.info("‚úÖ Valid√°ci√≥ OK, nincs DB m√≥dos√≠t√°s")
                return True
            
            # 2. DB csatlakoz√°s
            self.db = StockDatabase(self.mysql_config)
            if not self.db.connect():
                return False
            
            # 3. NYSE √©s NASDAQ feldolgoz√°sa
            for exchange_name in ['NYSE', 'NASDAQ']:
                self._process_exchange(df, exchange_name)
            
            self.db.disconnect()
            
            # 4. Statisztika
            self._print_stats()
            
            logger.info("=" * 70)
            logger.info("‚úÖ ETL Pipeline K√âSZ")
            logger.info("=" * 70)
            
            return True
        
        except Exception as e:
            logger.error(f"‚ùå ETL hiba: {e}", exc_info=True)
            if self.db:
                self.db.disconnect()
            return False
    
    def _process_exchange(self, df: pd.DataFrame, exchange_name: str):
        """Exchange feldolgoz√°sa"""
        logger.info(f"\nüìä {exchange_name} feldolgoz√°sa...")
        
        exchange_id = self.db.get_exchange_id(exchange_name)
        if not exchange_id:
            logger.warning(f"‚ö†Ô∏è {exchange_name} kihagyva (nincs DB-ben)")
            return
        
        # NYSE/NASDAQ sz≈±r√©s (Wikipedia nem jel√∂li, √≠gy mindent feldolgozunk)
        for idx, row in df.iterrows():
            stock_data = {
                'ticker': row['Symbol'],
                'company_name': row['Security'],
                'sector': row.get('GICSSector'),  # Updated column name (no space)
                'industry': row.get('GICS Sub-Industry'),
            }
            
            success, action = self.db.upsert_stock(
                stock_data, exchange_id, self.dry_run
            )
            
            if success:
                if action == 'INSERT' or action == 'INSERT (dry-run)':
                    self.stats['inserted'] += 1
                elif action == 'UPDATE' or action == 'UPDATE (dry-run)':
                    self.stats['updated'] += 1
                elif action == 'SKIP':
                    self.stats['skipped'] += 1
            else:
                self.stats['errors'] += 1
    
    def _print_stats(self):
        """Statisztika ki√≠r√°sa"""
        logger.info("\n" + "=" * 70)
        logger.info("üìà FUT√ÅS STATISZTIKA")
        logger.info("=" * 70)
        logger.info(f"  Feldolgozott sorok:  {self.stats['total_rows']}")
        logger.info(f"  Besz√∫rt:             {self.stats['inserted']}")
        logger.info(f"  Friss√≠tett:          {self.stats['updated']}")
        logger.info(f"  √Åtugrott:            {self.stats['skipped']}")
        logger.info(f"  Hib√°k:               {self.stats['errors']}")
        logger.info("=" * 70)

# ============================================================================
# MAIN
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='S&P 500 ETL Pipeline - Wikipedia ‚Üí MySQL'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Csak logol√°s, nincs DB m√≥dos√≠t√°s'
    )
    parser.add_argument(
        '--validate',
        action='store_true',
        help='Csak Wiki valid√°ci√≥, nincs DB m√≥dos√≠t√°s'
    )
    parser.add_argument(
        '--full',
        action='store_true',
        help='Teljes sync (alap√©rtelmezett)'
    )
    parser.add_argument(
        '--host',
        default='192.168.10.100',
        help='MySQL host (default: 192.168.10.100)'
    )
    parser.add_argument(
        '--user',
        default='webServer',
        help='MySQL user (default: webServer)'
    )
    parser.add_argument(
        '--password',
        default='webServer192.168.20.100',
        help='MySQL password'
    )
    parser.add_argument(
        '--database',
        default='newscred',
        help='Database name (default: newscred)'
    )
    
    args = parser.parse_args()
    
    # Config m√≥dos√≠t√°sa
    config = MYSQL_CONFIG.copy()
    config['host'] = args.host
    config['user'] = args.user
    config['password'] = args.password
    config['database'] = args.database
    
    # ETL futtat√°s
    pipeline = SP500ETLPipeline(
        mysql_config=config,
        dry_run=args.dry_run,
        validate_only=args.validate
    )
    
    success = pipeline.run()
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()
